{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "601e8d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    PolynomialFeatures,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import mlflow.keras\n",
    "from mlflow.models.signature import infer_signature\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError as RMSE, R2Score\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d6d9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(poly_features: int = 1):\n",
    "    # Get Data\n",
    "    data = pl.read_parquet(\"data.parquet\")\n",
    "    data = data.drop([\"Step\", \"Light_ID\", \"Lane\", \"Intersection_u\", \"Sim_ID\"])\n",
    "    data = data.with_columns(pl.col(\"Is_Entrypoint\").cast(pl.Int8))\n",
    "    print(f\"Data: {data.shape}\")\n",
    "    print(f\"{data.collect_schema()}\")\n",
    "\n",
    "    # Split Data\n",
    "    X = data.drop(\"Num_Cars\").to_numpy()\n",
    "    y = data.select(pl.col(\"Num_Cars\")).to_numpy()\n",
    "    y = y.ravel()\n",
    "    print(\"\")\n",
    "    print(f\"X: {X.shape}\")\n",
    "    print(f\"y: {y.shape}\")\n",
    "\n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Polynomial Features\n",
    "    if poly_features > 1:\n",
    "        poly = PolynomialFeatures(degree=poly_features)\n",
    "        X = poly.fit_transform(X)\n",
    "\n",
    "    # Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=0.6, test_size=0.4, random_state=42\n",
    "    )\n",
    "    print(\"\")\n",
    "    print(f\"X_train: {X_train.shape}\")\n",
    "    print(f\"X_test: {X_test.shape}\")\n",
    "    print(f\"y_train: {y_train.shape}\")\n",
    "    print(f\"y_test {y_test.shape}\")\n",
    "\n",
    "    # Train Test Validation Split\n",
    "    X_test, X_val, y_test, y_val = train_test_split(\n",
    "        X_test, y_test, train_size=0.5, test_size=0.5, random_state=42\n",
    "    )\n",
    "    print(\"\")\n",
    "    print(f\"X_test: {X_test.shape}\")\n",
    "    print(f\"X_val: {X_val.shape}\")\n",
    "    print(f\"y_test: {y_test.shape}\")\n",
    "    print(f\"y_val: {y_val.shape}\")\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd56fd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (6610000, 5)\n",
      "Schema({'Time': Int16, 'Num_Cars': Int16, 'Centrality': Float32, 'Is_Entrypoint': Int8, 'Distance': Int16})\n",
      "\n",
      "X: (6610000, 4)\n",
      "y: (6610000,)\n",
      "\n",
      "X_train: (3966000, 4)\n",
      "X_test: (2644000, 4)\n",
      "y_train: (3966000,)\n",
      "y_test (2644000,)\n",
      "\n",
      "X_test: (1322000, 4)\n",
      "X_val: (1322000, 4)\n",
      "y_test: (1322000,)\n",
      "y_val: (1322000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60752761",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43171416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 491us/step - loss: 2.0758 - r2_score: 0.1582 - root_mean_squared_error: 1.4407 - val_loss: 2.0347 - val_r2_score: 0.1704 - val_root_mean_squared_error: 1.4264\n",
      "Epoch 2/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 468us/step - loss: 2.0360 - r2_score: 0.1726 - root_mean_squared_error: 1.4269 - val_loss: 2.0235 - val_r2_score: 0.1750 - val_root_mean_squared_error: 1.4225\n",
      "Epoch 3/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 462us/step - loss: 2.0249 - r2_score: 0.1759 - root_mean_squared_error: 1.4230 - val_loss: 2.0225 - val_r2_score: 0.1754 - val_root_mean_squared_error: 1.4221\n",
      "Epoch 4/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 463us/step - loss: 2.0172 - r2_score: 0.1783 - root_mean_squared_error: 1.4203 - val_loss: 2.0217 - val_r2_score: 0.1757 - val_root_mean_squared_error: 1.4219\n",
      "Epoch 5/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 461us/step - loss: 2.0200 - r2_score: 0.1795 - root_mean_squared_error: 1.4213 - val_loss: 2.0150 - val_r2_score: 0.1784 - val_root_mean_squared_error: 1.4195\n",
      "Epoch 6/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 461us/step - loss: 2.0157 - r2_score: 0.1800 - root_mean_squared_error: 1.4198 - val_loss: 2.0107 - val_r2_score: 0.1802 - val_root_mean_squared_error: 1.4180\n",
      "Epoch 7/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 463us/step - loss: 2.0159 - r2_score: 0.1804 - root_mean_squared_error: 1.4198 - val_loss: 2.0150 - val_r2_score: 0.1784 - val_root_mean_squared_error: 1.4195\n",
      "Epoch 8/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 461us/step - loss: 2.0193 - r2_score: 0.1798 - root_mean_squared_error: 1.4210 - val_loss: 2.0078 - val_r2_score: 0.1814 - val_root_mean_squared_error: 1.4170\n",
      "Epoch 9/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 462us/step - loss: 2.0214 - r2_score: 0.1802 - root_mean_squared_error: 1.4217 - val_loss: 2.0118 - val_r2_score: 0.1797 - val_root_mean_squared_error: 1.4184\n",
      "Epoch 10/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 463us/step - loss: 2.0173 - r2_score: 0.1808 - root_mean_squared_error: 1.4203 - val_loss: 2.0100 - val_r2_score: 0.1805 - val_root_mean_squared_error: 1.4177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/11 18:09:15 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/04/11 18:09:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 2.013606548309326\n",
      "RMSE: 1.4190160036087036\n",
      "R2Score: 0.18041473627090454\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = \"Adam\"\n",
    "LR = 0.001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(32, activation=\"relu\"),\n",
    "            Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    model.build(input_shape=(None, X_train.shape[1]))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LR), loss=\"mse\", metrics=[RMSE(), R2Score()]\n",
    "    )\n",
    "\n",
    "    mlflow.log_param(\"optimizer\", OPTIMIZER)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        mlflow.log_metric(\"train_loss\", history.history[\"loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"train_rmse\", history.history[\"root_mean_squared_error\"][epoch], step=epoch\n",
    "        )\n",
    "        mlflow.log_metric(\"train_r2\", history.history[\"r2_score\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"val_rmse\",\n",
    "            history.history[\"val_root_mean_squared_error\"][epoch],\n",
    "            step=epoch,\n",
    "        )\n",
    "        mlflow.log_metric(\"val_r2\", history.history[\"val_r2_score\"][epoch], step=epoch)\n",
    "\n",
    "    loss, rmse, r2_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    mlflow.log_metric(\"test_loss\", loss)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_r2\", r2_score)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"R2Score: {r2_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48bb6af",
   "metadata": {},
   "source": [
    "## Add Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9ca45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 510us/step - loss: 2.0709 - r2_score: 0.1579 - root_mean_squared_error: 1.4390 - val_loss: 2.0284 - val_r2_score: 0.1730 - val_root_mean_squared_error: 1.4242\n",
      "Epoch 2/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 516us/step - loss: 2.0369 - r2_score: 0.1721 - root_mean_squared_error: 1.4272 - val_loss: 2.0172 - val_r2_score: 0.1775 - val_root_mean_squared_error: 1.4203\n",
      "Epoch 3/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 514us/step - loss: 2.0368 - r2_score: 0.1754 - root_mean_squared_error: 1.4271 - val_loss: 2.0235 - val_r2_score: 0.1750 - val_root_mean_squared_error: 1.4225\n",
      "Epoch 4/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 515us/step - loss: 2.0173 - r2_score: 0.1770 - root_mean_squared_error: 1.4203 - val_loss: 2.0193 - val_r2_score: 0.1767 - val_root_mean_squared_error: 1.4210\n",
      "Epoch 5/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 514us/step - loss: 2.0187 - r2_score: 0.1778 - root_mean_squared_error: 1.4208 - val_loss: 2.0167 - val_r2_score: 0.1778 - val_root_mean_squared_error: 1.4201\n",
      "Epoch 6/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 517us/step - loss: 2.0231 - r2_score: 0.1774 - root_mean_squared_error: 1.4223 - val_loss: 2.0413 - val_r2_score: 0.1677 - val_root_mean_squared_error: 1.4287\n",
      "Epoch 7/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 517us/step - loss: 2.0259 - r2_score: 0.1790 - root_mean_squared_error: 1.4233 - val_loss: 2.0093 - val_r2_score: 0.1808 - val_root_mean_squared_error: 1.4175\n",
      "Epoch 8/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 518us/step - loss: 2.0183 - r2_score: 0.1790 - root_mean_squared_error: 1.4207 - val_loss: 2.0162 - val_r2_score: 0.1780 - val_root_mean_squared_error: 1.4199\n",
      "Epoch 9/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 516us/step - loss: 2.0169 - r2_score: 0.1798 - root_mean_squared_error: 1.4202 - val_loss: 2.0312 - val_r2_score: 0.1718 - val_root_mean_squared_error: 1.4252\n",
      "Epoch 10/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 518us/step - loss: 2.0243 - r2_score: 0.1798 - root_mean_squared_error: 1.4228 - val_loss: 2.0178 - val_r2_score: 0.1773 - val_root_mean_squared_error: 1.4205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/12 00:42:52 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/04/12 00:42:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 2.0207467079162598\n",
      "RMSE: 1.4215296506881714\n",
      "R2Score: 0.17750853300094604\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = \"Adam\"\n",
    "LR = 0.001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(32, activation=\"relu\"),\n",
    "            Dense(16, activation=\"relu\"),\n",
    "            Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    model.build(input_shape=(None, X_train.shape[1]))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LR), loss=\"mse\", metrics=[RMSE(), R2Score()]\n",
    "    )\n",
    "\n",
    "    mlflow.log_param(\"optimizer\", OPTIMIZER)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        mlflow.log_metric(\"train_loss\", history.history[\"loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"train_rmse\", history.history[\"root_mean_squared_error\"][epoch], step=epoch\n",
    "        )\n",
    "        mlflow.log_metric(\"train_r2\", history.history[\"r2_score\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"val_rmse\",\n",
    "            history.history[\"val_root_mean_squared_error\"][epoch],\n",
    "            step=epoch,\n",
    "        )\n",
    "        mlflow.log_metric(\"val_r2\", history.history[\"val_r2_score\"][epoch], step=epoch)\n",
    "\n",
    "    loss, rmse, r2_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    mlflow.log_metric(\"test_loss\", loss)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_r2\", r2_score)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"R2Score: {r2_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d945ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2024s\u001b[0m 16ms/step - loss: 2.0742 - r2_score: 0.1570 - root_mean_squared_error: 1.4402 - val_loss: 2.0292 - val_r2_score: 0.1726 - val_root_mean_squared_error: 1.4245\n",
      "Epoch 2/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1928s\u001b[0m 16ms/step - loss: 2.0381 - r2_score: 0.1716 - root_mean_squared_error: 1.4276 - val_loss: 2.0222 - val_r2_score: 0.1755 - val_root_mean_squared_error: 1.4220\n",
      "Epoch 3/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1000s\u001b[0m 8ms/step - loss: 2.0271 - r2_score: 0.1757 - root_mean_squared_error: 1.4238 - val_loss: 2.0219 - val_r2_score: 0.1756 - val_root_mean_squared_error: 1.4219\n",
      "Epoch 4/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1964s\u001b[0m 16ms/step - loss: 2.0288 - r2_score: 0.1774 - root_mean_squared_error: 1.4244 - val_loss: 2.0145 - val_r2_score: 0.1786 - val_root_mean_squared_error: 1.4193\n",
      "Epoch 5/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 3ms/step - loss: 2.0251 - r2_score: 0.1775 - root_mean_squared_error: 1.4230 - val_loss: 2.0139 - val_r2_score: 0.1789 - val_root_mean_squared_error: 1.4191\n",
      "Epoch 6/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1099s\u001b[0m 9ms/step - loss: 2.0183 - r2_score: 0.1779 - root_mean_squared_error: 1.4206 - val_loss: 2.0145 - val_r2_score: 0.1786 - val_root_mean_squared_error: 1.4193\n",
      "Epoch 7/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2091s\u001b[0m 17ms/step - loss: 2.0197 - r2_score: 0.1793 - root_mean_squared_error: 1.4211 - val_loss: 2.0143 - val_r2_score: 0.1787 - val_root_mean_squared_error: 1.4193\n",
      "Epoch 8/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1059s\u001b[0m 9ms/step - loss: 2.0229 - r2_score: 0.1791 - root_mean_squared_error: 1.4223 - val_loss: 2.0145 - val_r2_score: 0.1786 - val_root_mean_squared_error: 1.4193\n",
      "Epoch 9/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1015s\u001b[0m 8ms/step - loss: 2.0259 - r2_score: 0.1768 - root_mean_squared_error: 1.4233 - val_loss: 2.0179 - val_r2_score: 0.1772 - val_root_mean_squared_error: 1.4205\n",
      "Epoch 10/10\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1981s\u001b[0m 16ms/step - loss: 2.0144 - r2_score: 0.1784 - root_mean_squared_error: 1.4193 - val_loss: 2.0144 - val_r2_score: 0.1787 - val_root_mean_squared_error: 1.4193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/12 04:49:10 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/04/12 04:49:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 2.018677234649658\n",
      "RMSE: 1.4208016395568848\n",
      "R2Score: 0.17835086584091187\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = \"Adam\"\n",
    "LR = 0.001\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(32, activation=\"relu\"),\n",
    "            Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    model.build(input_shape=(None, X_train.shape[1]))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LR), loss=\"mse\", metrics=[RMSE(), R2Score()]\n",
    "    )\n",
    "\n",
    "    mlflow.log_param(\"optimizer\", OPTIMIZER)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        mlflow.log_metric(\"train_loss\", history.history[\"loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"train_rmse\", history.history[\"root_mean_squared_error\"][epoch], step=epoch\n",
    "        )\n",
    "        mlflow.log_metric(\"train_r2\", history.history[\"r2_score\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"val_rmse\",\n",
    "            history.history[\"val_root_mean_squared_error\"][epoch],\n",
    "            step=epoch,\n",
    "        )\n",
    "        mlflow.log_metric(\"val_r2\", history.history[\"val_r2_score\"][epoch], step=epoch)\n",
    "\n",
    "    loss, rmse, r2_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    mlflow.log_metric(\"test_loss\", loss)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_r2\", r2_score)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"R2Score: {r2_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1620286a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 661us/step - loss: 2.0761 - r2_score: 0.1569 - root_mean_squared_error: 1.4408 - val_loss: 2.0386 - val_r2_score: 0.1688 - val_root_mean_squared_error: 1.4278\n",
      "Epoch 2/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 664us/step - loss: 2.0339 - r2_score: 0.1703 - root_mean_squared_error: 1.4261 - val_loss: 2.0366 - val_r2_score: 0.1696 - val_root_mean_squared_error: 1.4271\n",
      "Epoch 3/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 665us/step - loss: 2.0426 - r2_score: 0.1728 - root_mean_squared_error: 1.4292 - val_loss: 2.0247 - val_r2_score: 0.1745 - val_root_mean_squared_error: 1.4229\n",
      "Epoch 4/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 670us/step - loss: 2.0259 - r2_score: 0.1761 - root_mean_squared_error: 1.4233 - val_loss: 2.0216 - val_r2_score: 0.1758 - val_root_mean_squared_error: 1.4218\n",
      "Epoch 5/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 681us/step - loss: 2.0215 - r2_score: 0.1767 - root_mean_squared_error: 1.4218 - val_loss: 2.0154 - val_r2_score: 0.1783 - val_root_mean_squared_error: 1.4196\n",
      "Epoch 6/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 676us/step - loss: 2.0275 - r2_score: 0.1785 - root_mean_squared_error: 1.4239 - val_loss: 2.0153 - val_r2_score: 0.1783 - val_root_mean_squared_error: 1.4196\n",
      "Epoch 7/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 673us/step - loss: 2.0255 - r2_score: 0.1790 - root_mean_squared_error: 1.4232 - val_loss: 2.0262 - val_r2_score: 0.1739 - val_root_mean_squared_error: 1.4234\n",
      "Epoch 8/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 668us/step - loss: 2.0299 - r2_score: 0.1789 - root_mean_squared_error: 1.4247 - val_loss: 2.0115 - val_r2_score: 0.1799 - val_root_mean_squared_error: 1.4183\n",
      "Epoch 9/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 677us/step - loss: 2.0232 - r2_score: 0.1784 - root_mean_squared_error: 1.4224 - val_loss: 2.0232 - val_r2_score: 0.1751 - val_root_mean_squared_error: 1.4224\n",
      "Epoch 10/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 673us/step - loss: 2.0163 - r2_score: 0.1791 - root_mean_squared_error: 1.4200 - val_loss: 2.0212 - val_r2_score: 0.1759 - val_root_mean_squared_error: 1.4217\n",
      "Epoch 11/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 702us/step - loss: 2.0258 - r2_score: 0.1772 - root_mean_squared_error: 1.4233 - val_loss: 2.0127 - val_r2_score: 0.1794 - val_root_mean_squared_error: 1.4187\n",
      "Epoch 12/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1713s\u001b[0m 14ms/step - loss: 2.0195 - r2_score: 0.1793 - root_mean_squared_error: 1.4211 - val_loss: 2.0216 - val_r2_score: 0.1758 - val_root_mean_squared_error: 1.4218\n",
      "Epoch 13/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 673us/step - loss: 2.0105 - r2_score: 0.1794 - root_mean_squared_error: 1.4179 - val_loss: 2.0138 - val_r2_score: 0.1789 - val_root_mean_squared_error: 1.4191\n",
      "Epoch 14/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 675us/step - loss: 2.0203 - r2_score: 0.1791 - root_mean_squared_error: 1.4214 - val_loss: 2.0103 - val_r2_score: 0.1804 - val_root_mean_squared_error: 1.4178\n",
      "Epoch 15/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 684us/step - loss: 2.0220 - r2_score: 0.1797 - root_mean_squared_error: 1.4220 - val_loss: 2.0241 - val_r2_score: 0.1747 - val_root_mean_squared_error: 1.4227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/12 08:32:57 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/04/12 08:33:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 2.0284347534179688\n",
      "RMSE: 1.4242312908172607\n",
      "R2Score: 0.1743793487548828\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = \"Adam\"\n",
    "LR = 0.001\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(32, activation=\"relu\"),\n",
    "            Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    model.build(input_shape=(None, X_train.shape[1]))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LR), loss=\"mse\", metrics=[RMSE(), R2Score()]\n",
    "    )\n",
    "\n",
    "    mlflow.log_param(\"optimizer\", OPTIMIZER)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        mlflow.log_metric(\"train_loss\", history.history[\"loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"train_rmse\", history.history[\"root_mean_squared_error\"][epoch], step=epoch\n",
    "        )\n",
    "        mlflow.log_metric(\"train_r2\", history.history[\"r2_score\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"val_rmse\",\n",
    "            history.history[\"val_root_mean_squared_error\"][epoch],\n",
    "            step=epoch,\n",
    "        )\n",
    "        mlflow.log_metric(\"val_r2\", history.history[\"val_r2_score\"][epoch], step=epoch)\n",
    "\n",
    "    loss, rmse, r2_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    mlflow.log_metric(\"test_loss\", loss)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_r2\", r2_score)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"R2Score: {r2_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ba939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 513us/step - loss: 2.0723 - r2_score: 0.1572 - root_mean_squared_error: 1.4395 - val_loss: 2.0382 - val_r2_score: 0.1690 - val_root_mean_squared_error: 1.4277\n",
      "Epoch 2/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 508us/step - loss: 2.0323 - r2_score: 0.1734 - root_mean_squared_error: 1.4256 - val_loss: 2.0188 - val_r2_score: 0.1769 - val_root_mean_squared_error: 1.4209\n",
      "Epoch 3/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 511us/step - loss: 2.0254 - r2_score: 0.1771 - root_mean_squared_error: 1.4232 - val_loss: 2.0189 - val_r2_score: 0.1768 - val_root_mean_squared_error: 1.4209\n",
      "Epoch 4/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 511us/step - loss: 2.0211 - r2_score: 0.1778 - root_mean_squared_error: 1.4216 - val_loss: 2.0120 - val_r2_score: 0.1797 - val_root_mean_squared_error: 1.4185\n",
      "Epoch 5/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 514us/step - loss: 2.0182 - r2_score: 0.1781 - root_mean_squared_error: 1.4206 - val_loss: 2.0150 - val_r2_score: 0.1785 - val_root_mean_squared_error: 1.4195\n",
      "Epoch 6/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 515us/step - loss: 2.0231 - r2_score: 0.1789 - root_mean_squared_error: 1.4223 - val_loss: 2.0192 - val_r2_score: 0.1767 - val_root_mean_squared_error: 1.4210\n",
      "Epoch 7/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 525us/step - loss: 2.0225 - r2_score: 0.1793 - root_mean_squared_error: 1.4221 - val_loss: 2.0195 - val_r2_score: 0.1766 - val_root_mean_squared_error: 1.4211\n",
      "Epoch 8/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 516us/step - loss: 2.0153 - r2_score: 0.1796 - root_mean_squared_error: 1.4196 - val_loss: 2.0167 - val_r2_score: 0.1777 - val_root_mean_squared_error: 1.4201\n",
      "Epoch 9/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m969s\u001b[0m 8ms/step - loss: 2.0215 - r2_score: 0.1801 - root_mean_squared_error: 1.4218 - val_loss: 2.0122 - val_r2_score: 0.1796 - val_root_mean_squared_error: 1.4185\n",
      "Epoch 10/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2785s\u001b[0m 22ms/step - loss: 2.0140 - r2_score: 0.1802 - root_mean_squared_error: 1.4191 - val_loss: 2.0178 - val_r2_score: 0.1773 - val_root_mean_squared_error: 1.4205\n",
      "Epoch 11/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2809s\u001b[0m 23ms/step - loss: 2.0132 - r2_score: 0.1804 - root_mean_squared_error: 1.4189 - val_loss: 2.0078 - val_r2_score: 0.1814 - val_root_mean_squared_error: 1.4170\n",
      "Epoch 12/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2186s\u001b[0m 18ms/step - loss: 2.0151 - r2_score: 0.1807 - root_mean_squared_error: 1.4195 - val_loss: 2.0099 - val_r2_score: 0.1805 - val_root_mean_squared_error: 1.4177\n",
      "Epoch 13/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1715s\u001b[0m 14ms/step - loss: 2.0200 - r2_score: 0.1809 - root_mean_squared_error: 1.4213 - val_loss: 2.0141 - val_r2_score: 0.1788 - val_root_mean_squared_error: 1.4192\n",
      "Epoch 14/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 507us/step - loss: 2.0228 - r2_score: 0.1807 - root_mean_squared_error: 1.4222 - val_loss: 2.0092 - val_r2_score: 0.1808 - val_root_mean_squared_error: 1.4175\n",
      "Epoch 15/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 608us/step - loss: 2.0184 - r2_score: 0.1802 - root_mean_squared_error: 1.4207 - val_loss: 2.0128 - val_r2_score: 0.1793 - val_root_mean_squared_error: 1.4187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/12 12:16:17 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/04/12 12:16:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 2.0164895057678223\n",
      "RMSE: 1.4200315475463867\n",
      "R2Score: 0.17924129962921143\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = \"Adam\"\n",
    "LR = 0.001\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(32, activation=\"relu\"),\n",
    "            Dense(16, activation=\"relu\"),\n",
    "            Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    model.build(input_shape=(None, X_train.shape[1]))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LR), loss=\"mse\", metrics=[RMSE(), R2Score()]\n",
    "    )\n",
    "\n",
    "    mlflow.log_param(\"optimizer\", OPTIMIZER)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        mlflow.log_metric(\"train_loss\", history.history[\"loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"train_rmse\", history.history[\"root_mean_squared_error\"][epoch], step=epoch\n",
    "        )\n",
    "        mlflow.log_metric(\"train_r2\", history.history[\"r2_score\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"val_rmse\",\n",
    "            history.history[\"val_root_mean_squared_error\"][epoch],\n",
    "            step=epoch,\n",
    "        )\n",
    "        mlflow.log_metric(\"val_r2\", history.history[\"val_r2_score\"][epoch], step=epoch)\n",
    "\n",
    "    loss, rmse, r2_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    mlflow.log_metric(\"test_loss\", loss)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_r2\", r2_score)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"R2Score: {r2_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c3c3626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 511us/step - loss: 2.0749 - r2_score: 0.1574 - root_mean_squared_error: 1.4404 - val_loss: 2.0538 - val_r2_score: 0.1626 - val_root_mean_squared_error: 1.4331\n",
      "Epoch 2/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 508us/step - loss: 2.0370 - r2_score: 0.1723 - root_mean_squared_error: 1.4272 - val_loss: 2.0286 - val_r2_score: 0.1729 - val_root_mean_squared_error: 1.4243\n",
      "Epoch 3/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 508us/step - loss: 2.0279 - r2_score: 0.1750 - root_mean_squared_error: 1.4240 - val_loss: 2.0170 - val_r2_score: 0.1776 - val_root_mean_squared_error: 1.4202\n",
      "Epoch 4/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 511us/step - loss: 2.0225 - r2_score: 0.1768 - root_mean_squared_error: 1.4221 - val_loss: 2.0138 - val_r2_score: 0.1789 - val_root_mean_squared_error: 1.4191\n",
      "Epoch 5/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 510us/step - loss: 2.0233 - r2_score: 0.1778 - root_mean_squared_error: 1.4224 - val_loss: 2.0265 - val_r2_score: 0.1738 - val_root_mean_squared_error: 1.4235\n",
      "Epoch 6/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 509us/step - loss: 2.0204 - r2_score: 0.1779 - root_mean_squared_error: 1.4214 - val_loss: 2.0310 - val_r2_score: 0.1719 - val_root_mean_squared_error: 1.4251\n",
      "Epoch 7/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 510us/step - loss: 2.0229 - r2_score: 0.1782 - root_mean_squared_error: 1.4223 - val_loss: 2.0124 - val_r2_score: 0.1795 - val_root_mean_squared_error: 1.4186\n",
      "Epoch 8/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 510us/step - loss: 2.0177 - r2_score: 0.1780 - root_mean_squared_error: 1.4204 - val_loss: 2.0116 - val_r2_score: 0.1798 - val_root_mean_squared_error: 1.4183\n",
      "Epoch 9/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 513us/step - loss: 2.0189 - r2_score: 0.1785 - root_mean_squared_error: 1.4209 - val_loss: 2.0306 - val_r2_score: 0.1721 - val_root_mean_squared_error: 1.4250\n",
      "Epoch 10/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 515us/step - loss: 2.0164 - r2_score: 0.1791 - root_mean_squared_error: 1.4200 - val_loss: 2.0133 - val_r2_score: 0.1791 - val_root_mean_squared_error: 1.4189\n",
      "Epoch 11/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 517us/step - loss: 2.0235 - r2_score: 0.1791 - root_mean_squared_error: 1.4225 - val_loss: 2.0187 - val_r2_score: 0.1769 - val_root_mean_squared_error: 1.4208\n",
      "Epoch 12/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 519us/step - loss: 2.0212 - r2_score: 0.1791 - root_mean_squared_error: 1.4217 - val_loss: 2.0169 - val_r2_score: 0.1777 - val_root_mean_squared_error: 1.4202\n",
      "Epoch 13/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 518us/step - loss: 2.0208 - r2_score: 0.1797 - root_mean_squared_error: 1.4215 - val_loss: 2.0199 - val_r2_score: 0.1765 - val_root_mean_squared_error: 1.4212\n",
      "Epoch 14/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 519us/step - loss: 2.0261 - r2_score: 0.1785 - root_mean_squared_error: 1.4234 - val_loss: 2.0131 - val_r2_score: 0.1792 - val_root_mean_squared_error: 1.4188\n",
      "Epoch 15/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 517us/step - loss: 2.0395 - r2_score: 0.1703 - root_mean_squared_error: 1.4281 - val_loss: 2.0120 - val_r2_score: 0.1797 - val_root_mean_squared_error: 1.4184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/12 15:30:39 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/04/12 15:30:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 2.015489339828491\n",
      "RMSE: 1.4196792840957642\n",
      "R2Score: 0.17964839935302734\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = \"Adam\"\n",
    "LR = 0.001\n",
    "DECAY = 0.96\n",
    "DECAY_STEPS = 100000\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "with mlflow.start_run():\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=LR,\n",
    "        decay_steps=DECAY_STEPS,\n",
    "        decay_rate=DECAY,\n",
    "        staircase=True,\n",
    "    )\n",
    "\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(32, activation=\"relu\"),\n",
    "            Dense(16, activation=\"relu\"),\n",
    "            Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    model.build(input_shape=(None, X_train.shape[1]))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LR), loss=\"mse\", metrics=[RMSE(), R2Score()]\n",
    "    )\n",
    "\n",
    "    mlflow.log_param(\"optimizer\", OPTIMIZER)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        mlflow.log_metric(\"train_loss\", history.history[\"loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"train_rmse\", history.history[\"root_mean_squared_error\"][epoch], step=epoch\n",
    "        )\n",
    "        mlflow.log_metric(\"train_r2\", history.history[\"r2_score\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"val_rmse\",\n",
    "            history.history[\"val_root_mean_squared_error\"][epoch],\n",
    "            step=epoch,\n",
    "        )\n",
    "        mlflow.log_metric(\"val_r2\", history.history[\"val_r2_score\"][epoch], step=epoch)\n",
    "\n",
    "    loss, rmse, r2_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    mlflow.log_metric(\"test_loss\", loss)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_r2\", r2_score)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"R2Score: {r2_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea624445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 811us/step - loss: 2.0753 - r2_score: 0.1567 - root_mean_squared_error: 1.4406 - val_loss: 2.0398 - val_r2_score: 0.1683 - val_root_mean_squared_error: 1.4282\n",
      "Epoch 2/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 666us/step - loss: 2.0345 - r2_score: 0.1719 - root_mean_squared_error: 1.4263 - val_loss: 2.0323 - val_r2_score: 0.1714 - val_root_mean_squared_error: 1.4256\n",
      "Epoch 3/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 683us/step - loss: 2.0333 - r2_score: 0.1753 - root_mean_squared_error: 1.4259 - val_loss: 2.0280 - val_r2_score: 0.1731 - val_root_mean_squared_error: 1.4241\n",
      "Epoch 4/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 741us/step - loss: 2.0278 - r2_score: 0.1764 - root_mean_squared_error: 1.4240 - val_loss: 2.0197 - val_r2_score: 0.1765 - val_root_mean_squared_error: 1.4212\n",
      "Epoch 5/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 742us/step - loss: 2.0349 - r2_score: 0.1760 - root_mean_squared_error: 1.4265 - val_loss: 2.0242 - val_r2_score: 0.1747 - val_root_mean_squared_error: 1.4227\n",
      "Epoch 6/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 775us/step - loss: 2.0266 - r2_score: 0.1772 - root_mean_squared_error: 1.4236 - val_loss: 2.0188 - val_r2_score: 0.1769 - val_root_mean_squared_error: 1.4208\n",
      "Epoch 7/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 785us/step - loss: 2.0304 - r2_score: 0.1761 - root_mean_squared_error: 1.4249 - val_loss: 2.0180 - val_r2_score: 0.1772 - val_root_mean_squared_error: 1.4206\n",
      "Epoch 8/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 737us/step - loss: 2.0259 - r2_score: 0.1780 - root_mean_squared_error: 1.4233 - val_loss: 2.0208 - val_r2_score: 0.1761 - val_root_mean_squared_error: 1.4215\n",
      "Epoch 9/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 778us/step - loss: 2.0202 - r2_score: 0.1775 - root_mean_squared_error: 1.4213 - val_loss: 2.0153 - val_r2_score: 0.1783 - val_root_mean_squared_error: 1.4196\n",
      "Epoch 10/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 703us/step - loss: 2.0195 - r2_score: 0.1775 - root_mean_squared_error: 1.4211 - val_loss: 2.0344 - val_r2_score: 0.1705 - val_root_mean_squared_error: 1.4263\n",
      "Epoch 11/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 773us/step - loss: 2.0329 - r2_score: 0.1736 - root_mean_squared_error: 1.4258 - val_loss: 2.0177 - val_r2_score: 0.1773 - val_root_mean_squared_error: 1.4205\n",
      "Epoch 12/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 769us/step - loss: 2.0214 - r2_score: 0.1780 - root_mean_squared_error: 1.4217 - val_loss: 2.0138 - val_r2_score: 0.1789 - val_root_mean_squared_error: 1.4191\n",
      "Epoch 13/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 689us/step - loss: 2.0266 - r2_score: 0.1789 - root_mean_squared_error: 1.4236 - val_loss: 2.0258 - val_r2_score: 0.1740 - val_root_mean_squared_error: 1.4233\n",
      "Epoch 14/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 680us/step - loss: 2.0272 - r2_score: 0.1779 - root_mean_squared_error: 1.4238 - val_loss: 2.0133 - val_r2_score: 0.1791 - val_root_mean_squared_error: 1.4189\n",
      "Epoch 15/15\n",
      "\u001b[1m123938/123938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 674us/step - loss: 2.0255 - r2_score: 0.1791 - root_mean_squared_error: 1.4232 - val_loss: 2.0148 - val_r2_score: 0.1785 - val_root_mean_squared_error: 1.4194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/13 13:48:23 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "\u001b[31m2025/04/13 13:48:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 2.0195181369781494\n",
      "RMSE: 1.4210975170135498\n",
      "R2Score: 0.17800861597061157\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = \"Adam\"\n",
    "LR = 0.001\n",
    "DECAY = 0.96\n",
    "DECAY_STEPS = 100000\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "with mlflow.start_run():\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=LR,\n",
    "        decay_steps=DECAY_STEPS,\n",
    "        decay_rate=DECAY,\n",
    "        staircase=True,\n",
    "    )\n",
    "\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(32, activation=\"relu\"),\n",
    "            Dense(1),\n",
    "        ]\n",
    "    )\n",
    "    model.build(input_shape=(None, X_train.shape[1]))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LR), loss=\"mse\", metrics=[RMSE(), R2Score()]\n",
    "    )\n",
    "\n",
    "    mlflow.log_param(\"optimizer\", OPTIMIZER)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        mlflow.log_metric(\"train_loss\", history.history[\"loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"train_rmse\", history.history[\"root_mean_squared_error\"][epoch], step=epoch\n",
    "        )\n",
    "        mlflow.log_metric(\"train_r2\", history.history[\"r2_score\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][epoch], step=epoch)\n",
    "        mlflow.log_metric(\n",
    "            \"val_rmse\",\n",
    "            history.history[\"val_root_mean_squared_error\"][epoch],\n",
    "            step=epoch,\n",
    "        )\n",
    "        mlflow.log_metric(\"val_r2\", history.history[\"val_r2_score\"][epoch], step=epoch)\n",
    "\n",
    "    loss, rmse, r2_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    mlflow.log_metric(\"test_loss\", loss)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "    mlflow.log_metric(\"test_r2\", r2_score)\n",
    "\n",
    "    mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "    print(\"\")\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"R2Score: {r2_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
