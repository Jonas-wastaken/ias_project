{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c60126",
   "metadata": {},
   "source": [
    "# Tune XGB Regressor Model\n",
    "\n",
    "This notebook is used to optimize an XGB Regressor Model\n",
    "\n",
    "A two-step hyperparameter tuning approach was used for the XGBoost regressor. Initially, the influence of individual hyperparameters was evaluated by varying one at a time while keeping others fixed, allowing identification of promising value ranges and their relative impact on model performance. Based on these insights, a focused random search was then conducted, sampling hyperparameter combinations within the refined ranges centered around the previously identified good base values. This method ensured a more efficient and informed search of the hyperparameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f63daaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    PolynomialFeatures,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error as rmse\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198d7fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(poly_features: int = 1):\n",
    "    # Get Data\n",
    "    data = pl.read_parquet(\"data.parquet\")\n",
    "    data = data.drop([\"Step\", \"Light_ID\", \"Lane\", \"Intersection_u\", \"Sim_ID\"])\n",
    "    data = data.with_columns(pl.col(\"Is_Entrypoint\").cast(pl.Int8))\n",
    "    print(f\"Data: {data.shape}\")\n",
    "    print(f\"{data.collect_schema()}\")\n",
    "\n",
    "    # Split Data\n",
    "    X = data.drop(\"Num_Cars\").to_numpy()\n",
    "    y = data.select(pl.col(\"Num_Cars\")).to_numpy()\n",
    "    y = y.ravel()\n",
    "    print(\"\")\n",
    "    print(f\"X: {X.shape}\")\n",
    "    print(f\"y: {y.shape}\")\n",
    "\n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Polynomial Features\n",
    "    if poly_features > 1:\n",
    "        poly = PolynomialFeatures(degree=poly_features)\n",
    "        X = poly.fit_transform(X)\n",
    "\n",
    "    # Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, train_size=0.6, test_size=0.4, random_state=42\n",
    "    )\n",
    "    print(\"\")\n",
    "    print(f\"X_train: {X_train.shape}\")\n",
    "    print(f\"X_test: {X_test.shape}\")\n",
    "    print(f\"y_train: {y_train.shape}\")\n",
    "    print(f\"y_test {y_test.shape}\")\n",
    "\n",
    "    # Train Test Validation Split\n",
    "    X_test, X_val, y_test, y_val = train_test_split(\n",
    "        X_test, y_test, train_size=0.5, test_size=0.5, random_state=42\n",
    "    )\n",
    "    print(\"\")\n",
    "    print(f\"X_test: {X_test.shape}\")\n",
    "    print(f\"X_val: {X_val.shape}\")\n",
    "    print(f\"y_test: {y_test.shape}\")\n",
    "    print(f\"y_val: {y_val.shape}\")\n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea81272c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: (6610000, 5)\n",
      "Schema({'Time': Int16, 'Num_Cars': Int16, 'Centrality': Float32, 'Is_Entrypoint': Int8, 'Distance': Int16})\n",
      "\n",
      "X: (6610000, 4)\n",
      "y: (6610000,)\n",
      "\n",
      "X_train: (3966000, 4)\n",
      "X_test: (2644000, 4)\n",
      "y_train: (3966000,)\n",
      "y_test (2644000,)\n",
      "\n",
      "X_test: (1322000, 4)\n",
      "X_val: (1322000, 4)\n",
      "y_test: (1322000,)\n",
      "y_val: (1322000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, X_val, y_train, y_test, y_val = get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa6e952",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec553c9e",
   "metadata": {},
   "source": [
    "Create a baseline for performance with all default Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa3c4df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.21278494596481323\n",
      "RMSE (Training Data): 1.3919494152069092\n",
      "R2 Score (Test Data): 0.20956403017044067\n",
      "RMSE (Test Data): 1.3935534954071045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [20:16:23] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/12 20:16:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "\n",
    "    model = XGBRegressor(n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9cb368",
   "metadata": {},
   "source": [
    "## Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ba261",
   "metadata": {},
   "source": [
    "The n_estimators parameter determines the number of trees (estimators) in the XGBoost model.\n",
    "\n",
    "Increasing n_estimators can improve the model’s performance by allowing it to learn more complex relationships in the data. However, a higher number of estimators also increases the model’s training time and computational resources required.\n",
    "\n",
    "Default is 100\n",
    "\n",
    "https://xgboosting.com/configure-xgboost-n_estimators-parameter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "641dc5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2222939133644104\n",
      "RMSE (Training Data): 1.3835170269012451\n",
      "R2 Score (Test Data): 0.21727150678634644\n",
      "RMSE (Test Data): 1.3867425918579102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [13:06:56] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 13:06:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 200\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS, random_state=RANDOM_STATE, n_estimators=N_ESTIMATORS\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acd883ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.22840863466262817\n",
      "RMSE (Training Data): 1.3780673742294312\n",
      "R2 Score (Test Data): 0.22170007228851318\n",
      "RMSE (Test Data): 1.3828141689300537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [20:16:54] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/12 20:16:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS, random_state=RANDOM_STATE, n_estimators=N_ESTIMATORS\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b272cfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=500,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2362128496170044\n",
      "RMSE (Training Data): 1.3710803985595703\n",
      "R2 Score (Test Data): 0.2262347936630249\n",
      "RMSE (Test Data): 1.3787797689437866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [20:17:20] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/12 20:17:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 500\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS, random_state=RANDOM_STATE, n_estimators=N_ESTIMATORS\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "16cd8c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=1000,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2459743618965149\n",
      "RMSE (Training Data): 1.362290859222412\n",
      "R2 Score (Test Data): 0.22950363159179688\n",
      "RMSE (Test Data): 1.3758642673492432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [20:18:11] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/12 20:18:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 1000\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS, random_state=RANDOM_STATE, n_estimators=N_ESTIMATORS\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862cddc6",
   "metadata": {},
   "source": [
    "## Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4c92f",
   "metadata": {},
   "source": [
    "The learning_rate parameter in XGBoost is an alias for the eta parameter, which controls the step size at each boosting iteration.\n",
    "\n",
    "The learning rate determines the contribution of each tree to the final outcome by scaling the weights of the features.\n",
    "\n",
    "A lower learning rate can lead to better generalization and reduced overfitting, while a higher learning rate may result in faster learning but suboptimal solutions.\n",
    "\n",
    "Default is 0.3\n",
    "\n",
    "https://xgboosting.com/configure-xgboost-learning_rate-parameter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96506daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.01, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.17912393808364868\n",
      "RMSE (Training Data): 1.4213975667953491\n",
      "R2 Score (Test Data): 0.17810559272766113\n",
      "RMSE (Test Data): 1.4210138320922852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:01:11] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:01:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.01\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a15e0831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.001, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.07236886024475098\n",
      "RMSE (Training Data): 1.5109999179840088\n",
      "R2 Score (Test Data): 0.07216638326644897\n",
      "RMSE (Test Data): 1.5098206996917725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:01:37] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:01:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.001\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a04a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.21185463666915894\n",
      "RMSE (Training Data): 1.392771601676941\n",
      "R2 Score (Test Data): 0.20865070819854736\n",
      "RMSE (Test Data): 1.3943583965301514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:02:00] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:02:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.1\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca22331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.15, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.21798813343048096\n",
      "RMSE (Training Data): 1.3873417377471924\n",
      "R2 Score (Test Data): 0.21378618478775024\n",
      "RMSE (Test Data): 1.3898266553878784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:02:29] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:02:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.15\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a566bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.2, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.22191280126571655\n",
      "RMSE (Training Data): 1.383855938911438\n",
      "R2 Score (Test Data): 0.2166287899017334\n",
      "RMSE (Test Data): 1.3873118162155151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:02:51] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:02:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.2\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b124e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.25, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.22642111778259277\n",
      "RMSE (Training Data): 1.3798410892486572\n",
      "R2 Score (Test Data): 0.22013872861862183\n",
      "RMSE (Test Data): 1.3842004537582397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:03:14] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:03:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.25\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cf61869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.3, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.22840863466262817\n",
      "RMSE (Training Data): 1.3780673742294312\n",
      "R2 Score (Test Data): 0.22170007228851318\n",
      "RMSE (Test Data): 1.3828141689300537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:03:35] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:03:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.3\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d35abd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2309439778327942\n",
      "RMSE (Training Data): 1.37580144405365\n",
      "R2 Score (Test Data): 0.22321468591690063\n",
      "RMSE (Test Data): 1.3814679384231567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:03:57] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:03:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada25b98",
   "metadata": {},
   "source": [
    "## Max Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab52070",
   "metadata": {},
   "source": [
    "The max_depth parameter determines the maximum depth of each tree in the XGBoost model. It is a regularization parameter that can help control overfitting by limiting the model’s complexity. max_depth accepts positive integer values, and the default value in XGBoost is 6.\n",
    "\n",
    "https://xgboosting.com/configure-xgboost-max_depth-parameter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12f24b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=25,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.320204496383667\n",
      "RMSE (Training Data): 1.2934983968734741\n",
      "R2 Score (Test Data): 0.10901790857315063\n",
      "RMSE (Test Data): 1.4795334339141846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:05:28] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:05:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 25\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c2ad517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=10,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2809116840362549\n",
      "RMSE (Training Data): 1.3303560018539429\n",
      "R2 Score (Test Data): 0.22061705589294434\n",
      "RMSE (Test Data): 1.3837758302688599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:06:04] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:06:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 10\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dc20e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.24233931303024292\n",
      "RMSE (Training Data): 1.3655705451965332\n",
      "R2 Score (Test Data): 0.2281225323677063\n",
      "RMSE (Test Data): 1.3770968914031982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:06:30] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:06:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3fb2c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2194962501525879\n",
      "RMSE (Training Data): 1.3860032558441162\n",
      "R2 Score (Test Data): 0.21521472930908203\n",
      "RMSE (Test Data): 1.3885635137557983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:06:59] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:07:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 5\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3487c6",
   "metadata": {},
   "source": [
    "## Min Child Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df500a",
   "metadata": {},
   "source": [
    "The min_child_weight parameter determines the minimum sum of instance weight (hessian) needed in a child node for a split to be made.\n",
    "\n",
    "It is a regularization parameter that can help control overfitting by preventing the creation of overly complex trees. min_child_weight accepts non-negative values, and the default value in XGBoost is 1.\n",
    "\n",
    "https://xgboosting.com/configure-xgboost-min_child_weight-parameter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "823b92a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.24233931303024292\n",
      "RMSE (Training Data): 1.3655705451965332\n",
      "R2 Score (Test Data): 0.2281225323677063\n",
      "RMSE (Test Data): 1.3770968914031982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:40:13] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:40:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 1\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "804e3473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.24233931303024292\n",
      "RMSE (Training Data): 1.3655705451965332\n",
      "R2 Score (Test Data): 0.2281225323677063\n",
      "RMSE (Test Data): 1.3770968914031982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:42:08] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:42:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 2\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce407ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2421284317970276\n",
      "RMSE (Training Data): 1.3657605648040771\n",
      "R2 Score (Test Data): 0.2276458740234375\n",
      "RMSE (Test Data): 1.3775219917297363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:42:49] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:42:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4447f",
   "metadata": {},
   "source": [
    "## Subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fedc2",
   "metadata": {},
   "source": [
    "The subsample parameter determines the fraction of observations to be randomly sampled for each tree during the model’s training process. It is a regularization technique that can help prevent overfitting by introducing randomness into the training data. subsample accepts values between 0 and 1, with 1 meaning that all observations are used for each tree. The default value of subsample in XGBoost is 1.\n",
    "\n",
    "https://xgboosting.com/configure-xgboost-subsample-parameter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1cfb07a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2421284317970276\n",
      "RMSE (Training Data): 1.3657605648040771\n",
      "R2 Score (Test Data): 0.2276458740234375\n",
      "RMSE (Test Data): 1.3775219917297363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:45:32] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:45:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "060fa598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.24120813608169556\n",
      "RMSE (Training Data): 1.3665895462036133\n",
      "R2 Score (Test Data): 0.2252511978149414\n",
      "RMSE (Test Data): 1.3796558380126953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:46:04] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:46:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 0.9\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "397c5845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2399202585220337\n",
      "RMSE (Training Data): 1.367748737335205\n",
      "R2 Score (Test Data): 0.2237309217453003\n",
      "RMSE (Test Data): 1.3810087442398071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:46:50] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:46:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 0.8\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92238230",
   "metadata": {},
   "source": [
    "## Col Sample by Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b91df97",
   "metadata": {},
   "source": [
    "The colsample_bytree parameter determines the fraction of features (columns) to be randomly sampled for each tree during the model’s training process. It is a regularization technique that can help prevent overfitting by reducing the number of features each tree can access, thus encouraging the model to rely on different subsets of features. colsample_bytree accepts values between 0 and 1, with 1 meaning that all features are available for each tree. The default value of colsample_bytree in XGBoost is 1.\n",
    "\n",
    "https://xgboosting.com/configure-xgboost-colsample_bytree-parameter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a65c4db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2421284317970276\n",
      "RMSE (Training Data): 1.3657605648040771\n",
      "R2 Score (Test Data): 0.2276458740234375\n",
      "RMSE (Test Data): 1.3775219917297363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:50:13] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:50:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "COLSAMPLE_BYTREE = 1.0\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "    mlflow.log_param(\"colsample_bytree\", COLSAMPLE_BYTREE)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE_BYTREE,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48714cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2324995994567871\n",
      "RMSE (Training Data): 1.3744091987609863\n",
      "R2 Score (Test Data): 0.22353607416152954\n",
      "RMSE (Test Data): 1.3811821937561035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:51:16] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:51:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "COLSAMPLE_BYTREE = 0.9\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "    mlflow.log_param(\"colsample_bytree\", COLSAMPLE_BYTREE)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE_BYTREE,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5cb06dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2324995994567871\n",
      "RMSE (Training Data): 1.3744091987609863\n",
      "R2 Score (Test Data): 0.22353607416152954\n",
      "RMSE (Test Data): 1.3811821937561035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:52:19] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:52:21 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "COLSAMPLE_BYTREE = 0.8\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "    mlflow.log_param(\"colsample_bytree\", COLSAMPLE_BYTREE)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE_BYTREE,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101fa948",
   "metadata": {},
   "source": [
    "## Gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a13e29",
   "metadata": {},
   "source": [
    "The gamma parameter is a regularization term that governs the minimum loss reduction needed for a split to occur.\n",
    "\n",
    "In other words, it specifies the minimum improvement in the model’s objective function that a new partition must bring to justify its creation. gamma is a non-negative value, and higher values make the model more conservative.\n",
    "\n",
    "The default value of gamma in XGBoost is 0.\n",
    "\n",
    "https://xgboosting.com/configure-xgboost-gamma-parameter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "069298c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=0.0, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2421284317970276\n",
      "RMSE (Training Data): 1.3657605648040771\n",
      "R2 Score (Test Data): 0.2276458740234375\n",
      "RMSE (Test Data): 1.3775219917297363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:54:05] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:54:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "COLSAMPLE_BYTREE = 1.0\n",
    "GAMMA = 0.0\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "    mlflow.log_param(\"colsample_bytree\", COLSAMPLE_BYTREE)\n",
    "    mlflow.log_param(\"gamma\", GAMMA)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE_BYTREE,\n",
    "        gamma=GAMMA,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0d87600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=1.0, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.22192102670669556\n",
      "RMSE (Training Data): 1.3838486671447754\n",
      "R2 Score (Test Data): 0.21626973152160645\n",
      "RMSE (Test Data): 1.3876298666000366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:53:08] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:53:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "COLSAMPLE_BYTREE = 1.0\n",
    "GAMMA = 1.0\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "    mlflow.log_param(\"colsample_bytree\", COLSAMPLE_BYTREE)\n",
    "    mlflow.log_param(\"gamma\", GAMMA)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE_BYTREE,\n",
    "        gamma=GAMMA,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67d1af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=0.3, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2324044108390808\n",
      "RMSE (Training Data): 1.3744945526123047\n",
      "R2 Score (Test Data): 0.22302556037902832\n",
      "RMSE (Test Data): 1.3816360235214233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:54:40] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:54:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "COLSAMPLE_BYTREE = 1.0\n",
    "GAMMA = 0.3\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "    mlflow.log_param(\"colsample_bytree\", COLSAMPLE_BYTREE)\n",
    "    mlflow.log_param(\"gamma\", GAMMA)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE_BYTREE,\n",
    "        gamma=GAMMA,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2e1f055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=0.1, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.23941928148269653\n",
      "RMSE (Training Data): 1.3681994676589966\n",
      "R2 Score (Test Data): 0.22676622867584229\n",
      "RMSE (Test Data): 1.378306269645691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:55:07] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:55:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "COLSAMPLE_BYTREE = 1.0\n",
    "GAMMA = 0.1\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "    mlflow.log_param(\"colsample_bytree\", COLSAMPLE_BYTREE)\n",
    "    mlflow.log_param(\"gamma\", GAMMA)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE_BYTREE,\n",
    "        gamma=GAMMA,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d64387",
   "metadata": {},
   "source": [
    "## Reg Alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207cbeb3",
   "metadata": {},
   "source": [
    "The reg_alpha parameter in XGBoost is an alias for the alpha parameter, which controls the L1 regularization term on weights. By adjusting reg_alpha, you can influence the model’s complexity and sparsity. Default is 0.\n",
    "\n",
    "https://xgboosting.com/configure-xgboost-reg_alpha-parameter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78d29e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=0.0, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.2421284317970276\n",
      "RMSE (Training Data): 1.3657605648040771\n",
      "R2 Score (Test Data): 0.2276458740234375\n",
      "RMSE (Test Data): 1.3775219917297363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [13:16:59] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 13:17:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "COLSAMPLE_BYTREE = 1.0\n",
    "GAMMA = 0.0\n",
    "REG_ALPHA = 0.0\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "    mlflow.log_param(\"colsample_bytree\", COLSAMPLE_BYTREE)\n",
    "    mlflow.log_param(\"gamma\", GAMMA)\n",
    "    mlflow.log_param(\"reg_alpha\", REG_ALPHA)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE_BYTREE,\n",
    "        gamma=GAMMA,\n",
    "        reg_alpha=REG_ALPHA,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "06a506bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=0.0, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.24177467823028564\n",
      "RMSE (Training Data): 1.3660792112350464\n",
      "R2 Score (Test Data): 0.22749465703964233\n",
      "RMSE (Test Data): 1.3776568174362183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:57:17] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:57:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "COLSAMPLE_BYTREE = 1.0\n",
    "GAMMA = 0.0\n",
    "REG_ALPHA = 0.2\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "    mlflow.log_param(\"colsample_bytree\", COLSAMPLE_BYTREE)\n",
    "    mlflow.log_param(\"gamma\", GAMMA)\n",
    "    mlflow.log_param(\"reg_alpha\", REG_ALPHA)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE_BYTREE,\n",
    "        gamma=GAMMA,\n",
    "        reg_alpha=REG_ALPHA,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f89a6e",
   "metadata": {},
   "source": [
    "## Reg Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c2f49",
   "metadata": {},
   "source": [
    "The reg_lambda parameter in XGBoost is an alias for the lambda parameter, which controls the L2 regularization term on weights. By adjusting reg_lambda, you can influence the model’s complexity and its ability to generalize. Default value is 1.\n",
    "\n",
    "https://xgboosting.com/configure-xgboost-reg_lambda-parameter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f215984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=0.0, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.242112398147583\n",
      "RMSE (Training Data): 1.3657749891281128\n",
      "R2 Score (Test Data): 0.22756677865982056\n",
      "RMSE (Test Data): 1.3775924444198608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:58:40] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:58:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "COLSAMPLE_BYTREE = 1.0\n",
    "GAMMA = 0.0\n",
    "REG_ALPHA = 0.2\n",
    "REG_LAMBDA = 0.0\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "    mlflow.log_param(\"colsample_bytree\", COLSAMPLE_BYTREE)\n",
    "    mlflow.log_param(\"gamma\", GAMMA)\n",
    "    mlflow.log_param(\"reg_alpha\", REG_ALPHA)\n",
    "    mlflow.log_param(\"reg_lambda\", REG_LAMBDA)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE_BYTREE,\n",
    "        gamma=GAMMA,\n",
    "        reg_alpha=REG_ALPHA,\n",
    "        reg_lambda=REG_LAMBDA,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16f6f898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=0.0, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.35, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
      "             max_leaves=None, min_child_weight=3, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=300,\n",
      "             n_jobs=8, num_parallel_tree=None, ...)\n",
      "\n",
      "R2 Score (Training Data): 0.24194109439849854\n",
      "RMSE (Training Data): 1.365929365158081\n",
      "R2 Score (Test Data): 0.22797441482543945\n",
      "RMSE (Test Data): 1.3772289752960205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Work/git/ias_project/ml_training/.venv/lib/python3.12/site-packages/xgboost/sklearn.py:1028: UserWarning: [12:59:21] WARNING: /Users/runner/work/xgboost/xgboost/src/c_api/c_api.cc:1427: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "\u001b[31m2025/04/13 12:59:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "N_JOBS = os.cpu_count()\n",
    "RANDOM_STATE = 42\n",
    "N_ESTIMATORS = 300\n",
    "LR = 0.35\n",
    "MAX_DEPTH = 7\n",
    "MIN_CHILD_WEIGHT = 3\n",
    "SUBSAMPLE = 1.0\n",
    "COLSAMPLE_BYTREE = 1.0\n",
    "GAMMA = 0.0\n",
    "REG_ALPHA = 0.2\n",
    "REG_LAMBDA = 0.2\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_type\", \"XGBRegressor\")\n",
    "    mlflow.log_param(\"n_jobs\", N_JOBS)\n",
    "    mlflow.log_param(\"random_state\", RANDOM_STATE)\n",
    "    mlflow.log_param(\"n_estimators\", N_ESTIMATORS)\n",
    "    mlflow.log_param(\"learning_rate\", LR)\n",
    "    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n",
    "    mlflow.log_param(\"min_child_weight\", MIN_CHILD_WEIGHT)\n",
    "    mlflow.log_param(\"subsample\", SUBSAMPLE)\n",
    "    mlflow.log_param(\"colsample_bytree\", COLSAMPLE_BYTREE)\n",
    "    mlflow.log_param(\"gamma\", GAMMA)\n",
    "    mlflow.log_param(\"reg_alpha\", REG_ALPHA)\n",
    "    mlflow.log_param(\"reg_lambda\", REG_LAMBDA)\n",
    "\n",
    "    model = XGBRegressor(\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LR,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        min_child_weight=MIN_CHILD_WEIGHT,\n",
    "        subsample=SUBSAMPLE,\n",
    "        colsample_bytree=COLSAMPLE_BYTREE,\n",
    "        gamma=GAMMA,\n",
    "        reg_alpha=REG_ALPHA,\n",
    "        reg_lambda=REG_LAMBDA,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(model)\n",
    "    print(\"\")\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    train_r2 = r2_score(y_true=y_train, y_pred=y_pred_train)\n",
    "    train_rmse = rmse(y_true=y_train, y_pred=y_pred_train)\n",
    "\n",
    "    print(f\"R2 Score (Training Data): {train_r2}\")\n",
    "    print(f\"RMSE (Training Data): {train_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"train_r2\", train_r2)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    test_r2 = r2_score(y_true=y_test, y_pred=y_pred_test)\n",
    "    test_rmse = rmse(y_true=y_test, y_pred=y_pred_test)\n",
    "\n",
    "    print(f\"R2 Score (Test Data): {test_r2}\")\n",
    "    print(f\"RMSE (Test Data): {test_rmse}\")\n",
    "\n",
    "    mlflow.log_metric(\"test_r2\", test_r2)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    mlflow.xgboost.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea829ad3",
   "metadata": {},
   "source": [
    "## Random Search Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ea93b9",
   "metadata": {},
   "source": [
    "A two-step hyperparameter tuning approach was used for the XGBoost regressor. Initially, the influence of individual hyperparameters was evaluated by varying one at a time while keeping others fixed, allowing identification of promising value ranges and their relative impact on model performance. Based on these insights, a focused random search was then conducted, sampling hyperparameter combinations within the refined ranges centered around the previously identified good base values. This method ensured a more efficient and informed search of the hyperparameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2916ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.905 total time=  48.8s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.909 total time=  52.5s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.915 total time=  55.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.913 total time=  55.8s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.911 total time=  55.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.916 total time=  42.3s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.915 total time=  41.3s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  48.5s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=3, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.909 total time=  41.9s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.908 total time= 1.7min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.913 total time= 1.7min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.912 total time= 1.7min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=6, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.913 total time=  51.0s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=6, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.909 total time=  56.5s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=6, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.914 total time=  58.4s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.903 total time=  37.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.908 total time=  43.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=9, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.916 total time= 1.8min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=9, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.921 total time= 1.8min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=9, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.920 total time= 1.7min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=8, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.913 total time= 1.9min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=8, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.919 total time= 2.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=8, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.918 total time= 2.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time=  36.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=1, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.909 total time=  41.7s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=1, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.911 total time=  47.6s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=1, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.903 total time=  52.6s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.904 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=5, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time=  48.0s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=5, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.903 total time=  43.7s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.899 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=1, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.905 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=2, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.913 total time= 1.7min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=2, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.909 total time= 1.7min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=2, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.912 total time= 1.7min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=5, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  47.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=5, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.914 total time=  55.7s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=5, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.910 total time=  56.2s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=5, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.914 total time=  55.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time=  47.1s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.913 total time= 1.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.915 total time=  55.6s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.908 total time= 1.0min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.902 total time=  38.4s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.905 total time=  47.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=8, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.907 total time=  56.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.906 total time= 1.5min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.912 total time= 1.5min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=8, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.899 total time=  48.6s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.913 total time= 1.5min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.911 total time= 1.5min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time= 1.5min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=7, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.911 total time= 1.5min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=8, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.903 total time=  43.9s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=6, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.904 total time=  42.7s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=6, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.908 total time=  43.5s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=6, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  43.6s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=7, min_child_weight=4, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.909 total time=  52.3s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=7, min_child_weight=4, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.904 total time=  50.4s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=7, min_child_weight=4, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  51.6s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.905 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.900 total time= 1.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.906 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.906 total time=  43.5s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=8, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.915 total time= 1.7min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=2, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.918 total time= 1.5min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=2, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.914 total time= 1.4min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=8, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.909 total time= 1.7min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.901 total time=  40.9s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=8, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.915 total time= 1.7min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=2, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.918 total time= 1.4min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.906 total time=  45.5s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.909 total time=  45.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.902 total time=  47.6s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  46.7s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=7, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.910 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=7, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.906 total time= 1.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=7, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.910 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.904 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.910 total time= 1.0min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.905 total time= 1.0min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=2, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.915 total time=  44.2s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.898 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.904 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=2, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.909 total time=  42.6s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.911 total time=  59.6s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=2, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.914 total time=  41.7s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=6, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time=  41.8s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=6, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  41.4s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=6, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.901 total time=  44.7s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=9, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.905 total time=  49.7s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=9, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.900 total time=  50.1s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.910 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.905 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=9, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.910 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=9, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time=  44.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=8, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.905 total time=  49.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=8, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.901 total time=  48.8s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=8, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.905 total time=  47.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.903 total time= 1.4min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.898 total time= 1.4min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=7, min_child_weight=5, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.907 total time=  56.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=7, min_child_weight=5, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.904 total time=  54.1s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.904 total time= 1.4min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.908 total time=  39.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.913 total time=  52.1s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=7, min_child_weight=5, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.909 total time=  52.9s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.907 total time=  53.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.903 total time=  44.7s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.912 total time=  53.3s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.909 total time=  42.0s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.904 total time= 1.6min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=3, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=3, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.901 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.899 total time= 1.6min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=9, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.906 total time= 1.6min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.900 total time=  37.3s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.905 total time=  40.0s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.905 total time=  34.5s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=3, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  54.1s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.937 total time= 2.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.934 total time= 2.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.938 total time= 2.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=8, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.911 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.905 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.899 total time= 1.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=8, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=8, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.912 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=3, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.914 total time= 1.6min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=3, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.911 total time= 1.6min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=3, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.918 total time= 1.5min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.902 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.897 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.904 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.903 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.899 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=2, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.909 total time=  42.9s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.904 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=2, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.902 total time=  51.0s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=1, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.908 total time=  50.4s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=2, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.906 total time=  51.8s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=1, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.903 total time=  51.1s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.911 total time=  49.4s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=1, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time=  53.9s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.904 total time=  52.5s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=3, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.912 total time=  52.7s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.903 total time= 1.4min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.897 total time= 1.4min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.902 total time= 1.4min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.905 total time= 1.4min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.898 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=9, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.924 total time= 2.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=9, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.920 total time= 2.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=9, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.926 total time= 2.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.904 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=4, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.910 total time=  46.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.904 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.898 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=8, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.904 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.906 total time=  38.7s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=4, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.903 total time=  48.4s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=4, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.909 total time=  48.8s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.901 total time=  39.5s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=5, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.908 total time=  44.1s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=5, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.914 total time=  59.1s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=5, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.914 total time=  56.3s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=5, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.908 total time=  57.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.904 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.898 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.904 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=4, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.902 total time= 1.6min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  56.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=4, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.897 total time= 1.5min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.900 total time=  55.3s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=1, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=1, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.900 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=1, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.905 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=4, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.904 total time= 1.4min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.909 total time=  42.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=7, min_child_weight=3, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.911 total time=  43.0s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=7, min_child_weight=3, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.904 total time=  46.1s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=7, min_child_weight=3, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.910 total time=  55.5s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=9, min_child_weight=8, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.903 total time=  56.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=9, min_child_weight=8, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.898 total time=  56.1s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=9, min_child_weight=8, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.906 total time=  46.8s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.912 total time=  56.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=7, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.916 total time= 1.5min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=7, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.912 total time= 1.5min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=7, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.917 total time= 1.5min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  51.3s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.912 total time=  35.0s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=6, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.912 total time=  50.4s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.908 total time=  36.7s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.911 total time=  37.9s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=5, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time=  41.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=5, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.901 total time=  43.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=5, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time=  49.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=3, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.909 total time=  49.5s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.913 total time= 1.0min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.909 total time=  58.6s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.911 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=3, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.903 total time=  50.6s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=3, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  48.7s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.922 total time=  47.0s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.917 total time=  46.6s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.923 total time=  49.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=4, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.907 total time=  55.7s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=4, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.903 total time=  52.9s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=4, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.905 total time=  55.3s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=5, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.901 total time= 1.5min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=5, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.905 total time= 1.5min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=5, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.907 total time= 1.5min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=4, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.920 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=4, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.917 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.903 total time=  60.0s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.898 total time= 1.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=4, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.921 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.912 total time=  51.6s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.903 total time= 1.0min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.908 total time=  51.2s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.912 total time=  51.6s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.906 total time=  55.5s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.901 total time=  58.6s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time=  58.8s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.906 total time=  48.8s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.910 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.906 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.905 total time= 1.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.910 total time= 1.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=5, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.909 total time=  48.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.905 total time=  49.6s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.900 total time=  52.5s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  46.9s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  50.0s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.900 total time=  50.2s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.906 total time=  50.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.908 total time=  58.1s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.913 total time= 1.6min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.914 total time=  54.8s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.902 total time=  59.2s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.910 total time=  51.8s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.905 total time=  60.0s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time= 1.5min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=5, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.914 total time= 1.6min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=2, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.913 total time=  55.3s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=7, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.913 total time=  58.9s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=7, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.909 total time=  59.0s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=7, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.916 total time=  59.3s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=7, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time=  46.8s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=9, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.914 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=9, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.909 total time= 1.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=9, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.915 total time= 1.0min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=7, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.899 total time=  48.2s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=7, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time=  47.8s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=1, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.916 total time=  48.2s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=1, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.913 total time=  48.3s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=1, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.917 total time=  51.0s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  57.9s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.906 total time=  54.2s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=7, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time=  58.5s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=6, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.914 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.917 total time= 1.8min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.913 total time= 1.8min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.920 total time= 1.8min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=6, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.909 total time= 1.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=6, min_child_weight=6, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.914 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=8, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.906 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=7, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.916 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=8, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.900 total time= 1.4min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=8, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.906 total time= 1.4min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=7, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.910 total time= 1.0min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.907 total time=  41.6s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.900 total time=  41.4s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.907 total time=  38.8s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=7, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.914 total time=  56.5s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.923 total time= 2.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.928 total time= 2.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=2, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.928 total time= 2.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=2, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  41.3s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=2, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.909 total time=  43.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=2, n_estimators=250, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.904 total time=  47.0s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.906 total time= 1.6min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.901 total time= 1.6min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.906 total time= 1.6min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.916 total time= 1.6min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.911 total time= 1.6min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.917 total time= 1.6min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=1, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time=  47.8s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=1, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.909 total time=  47.8s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=1, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.900 total time=  50.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=3, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.912 total time=  51.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=2, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.944 total time= 2.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=2, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.942 total time= 2.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=3, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  50.6s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=3, n_estimators=300, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.912 total time=  54.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.918 total time=  58.6s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=2, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.946 total time= 2.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.914 total time=  58.3s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=4, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.918 total time=  57.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=2, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.907 total time=  49.3s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=9, min_child_weight=8, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.909 total time= 1.8min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=9, min_child_weight=8, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.903 total time= 1.8min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=2, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.903 total time=  41.1s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=9, min_child_weight=8, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.908 total time= 1.8min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=2, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.908 total time=  43.8s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=8, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.905 total time=  46.4s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=8, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.900 total time=  48.0s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=8, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time=  57.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.913 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.918 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.910 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.903 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.899 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.904 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=4, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.904 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=4, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.900 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.902 total time=  50.0s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.906 total time=  53.2s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=4, n_estimators=350, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time=  49.9s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=4, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.904 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.905 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.900 total time= 1.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=8, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.905 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.904 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.898 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=3, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.932 total time= 2.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=2, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.922 total time= 1.8min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=2, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.916 total time= 1.8min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=3, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.926 total time= 2.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=3, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.933 total time= 2.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=9, min_child_weight=2, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.921 total time= 1.8min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=8, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.914 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=8, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.912 total time= 1.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=8, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.905 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=8, n_estimators=400, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.915 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.914 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.912 total time= 1.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=4, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.913 total time= 1.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=2, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  44.1s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=2, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  52.6s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=2, n_estimators=250, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.905 total time=  54.6s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.912 total time= 1.0min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  59.5s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=4, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.929 total time= 2.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=9, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.909 total time=  44.0s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=6, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.914 total time=  50.3s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=9, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.902 total time=  46.8s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=8, min_child_weight=9, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.906 total time=  46.6s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=4, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.927 total time= 2.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=4, n_estimators=400, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.932 total time= 2.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=8, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.905 total time= 1.0min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=5, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.915 total time=  45.8s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=5, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.911 total time=  45.3s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=8, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.900 total time= 1.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=5, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.915 total time=  45.9s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.3, max_depth=7, min_child_weight=8, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.906 total time= 1.0min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.919 total time=  46.2s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.915 total time=  46.1s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=6, min_child_weight=5, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.918 total time=  46.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=1, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.914 total time=  59.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=1, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.910 total time=  59.2s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=1, n_estimators=300, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.915 total time=  59.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.911 total time=  53.1s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.903 total time= 1.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=1, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.908 total time=  57.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.910 total time= 1.0min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.905 total time=  59.0s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.905 total time=  44.6s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.901 total time=  47.4s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=5, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.911 total time=  53.5s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  46.7s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=1, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.908 total time=  50.8s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=1, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.903 total time=  53.1s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.905 total time= 1.7min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.900 total time= 1.7min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.921 total time= 1.5min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=8, min_child_weight=6, n_estimators=400, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time= 1.7min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.916 total time= 1.5min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=9, n_estimators=300, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.922 total time= 1.5min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=9, min_child_weight=1, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.908 total time=  39.6s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=4, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  52.8s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=4, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.902 total time= 1.0min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=4, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time=  58.6s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time=  59.6s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.901 total time=  58.7s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=1, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.942 total time= 1.8min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  50.8s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=1, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.939 total time= 1.9min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=1, n_estimators=350, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.944 total time= 1.9min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=4, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.910 total time=  52.9s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.903 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=4, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.905 total time=  51.0s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=6, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.908 total time= 1.2min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=7, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.908 total time=  41.8s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=7, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.903 total time=  41.3s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=7, min_child_weight=4, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.909 total time=  53.2s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=7, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.909 total time=  38.1s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.912 total time=  42.4s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  41.2s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=1, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.913 total time=  39.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=4, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.921 total time= 1.3min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=2, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.913 total time=  55.6s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=4, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.914 total time= 1.3min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=9, min_child_weight=4, n_estimators=250, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.922 total time= 1.3min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=2, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.904 total time= 1.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=2, n_estimators=350, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.910 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=1, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.908 total time=  52.0s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=1, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.903 total time=  51.2s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=1, n_estimators=300, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.906 total time=  53.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=4, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.909 total time=  43.0s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=5, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time= 1.5min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=5, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.903 total time= 1.5min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=4, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.903 total time=  38.8s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=9, min_child_weight=4, n_estimators=300, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.908 total time=  36.4s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=5, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.909 total time= 1.6min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=2, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.903 total time=  54.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=2, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  56.5s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=2, n_estimators=350, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  57.2s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  59.6s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.900 total time=  58.9s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.915 total time= 1.8min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.908 total time= 1.8min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time=  39.0s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=8, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.915 total time= 1.8min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=7, n_estimators=250, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.907 total time=  48.5s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.902 total time=  44.3s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.39999999999999997, max_depth=8, min_child_weight=6, n_estimators=350, reg_alpha=0, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time=  47.4s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.912 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.908 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.915 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.913 total time= 1.1min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=6, min_child_weight=7, n_estimators=400, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.915 total time= 1.1min\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=9, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.908 total time=  57.3s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.3, max_depth=6, min_child_weight=2, n_estimators=350, reg_alpha=0, reg_lambda=0.2, subsample=1.0;, score=-1.915 total time= 1.1min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=9, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.900 total time=  54.8s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=9, n_estimators=250, reg_alpha=0.1, reg_lambda=0.2, subsample=1.0;, score=-1.908 total time=  54.0s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=1, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.915 total time=  47.5s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=1, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.910 total time=  48.5s\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.44999999999999996, max_depth=6, min_child_weight=1, n_estimators=250, reg_alpha=0, reg_lambda=0, subsample=1.0;, score=-1.916 total time=  48.6s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=1, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.906 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=1, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.901 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.44999999999999996, max_depth=7, min_child_weight=1, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.906 total time= 1.2min\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=2, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.904 total time=  42.0s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=2, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.906 total time=  45.1s\n",
      "[CV 1/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.903 total time= 1.4min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.35, max_depth=8, min_child_weight=2, n_estimators=300, reg_alpha=0.1, reg_lambda=0.1, subsample=1.0;, score=-1.907 total time=  33.3s\n",
      "[CV 2/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.898 total time= 1.2min\n",
      "[CV 3/3] END colsample_bytree=1.0, gamma=0, learning_rate=0.35, max_depth=7, min_child_weight=6, n_estimators=400, reg_alpha=0.1, reg_lambda=0, subsample=1.0;, score=-1.903 total time= 1.1min\n",
      "R2 Score (Training Data): 0.2522403597831726\n",
      "RMSE (Training Data): 1.3566186428070068\n",
      "\n",
      "R2 Score (Test Data): 0.2297268509864807\n",
      "RMSE (Test Data): 1.3756650686264038\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    \"n_estimators\": np.arange(250, 450, 50),\n",
    "    \"learning_rate\": np.arange(0.3, 0.5, 0.05),\n",
    "    \"max_depth\": np.arange(6, 10, 1),\n",
    "    \"min_child_weight\": np.arange(1, 10, 1),\n",
    "    \"subsample\": [1.0],\n",
    "    \"colsample_bytree\": [1.0],\n",
    "    \"gamma\": [0, 0.1],\n",
    "    \"reg_alpha\": [0, 0.1],\n",
    "    \"reg_lambda\": [0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "model = XGBRegressor(random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=150,\n",
    "    cv=3,\n",
    "    verbose=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"neg_mean_squared_error\",\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_model: XGBRegressor = random_search.best_estimator_\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = best_model.predict(X_train)\n",
    "print(f\"R2 Score (Training Data): {r2_score(y_true=y_train, y_pred=y_pred)}\")\n",
    "print(f\"RMSE (Training Data): {rmse(y_true=y_train, y_pred=y_pred)}\")\n",
    "print(\"\")\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(f\"R2 Score (Test Data): {r2_score(y_true=y_test, y_pred=y_pred)}\")\n",
    "print(f\"RMSE (Test Data): {rmse(y_true=y_test, y_pred=y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c17b85",
   "metadata": {},
   "source": [
    "The hyperparameter search slightly improved model performance, with the best identified model being the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "21959208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=0, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=np.float64(0.3), max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=np.int64(8), max_leaves=None,\n",
       "             min_child_weight=np.int64(5), missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None,\n",
       "             n_estimators=np.int64(300), n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBRegressor\">?<span>Documentation for XGBRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=0, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=np.float64(0.3), max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=np.int64(8), max_leaves=None,\n",
       "             min_child_weight=np.int64(5), missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None,\n",
       "             n_estimators=np.int64(300), n_jobs=None, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=1.0, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             feature_weights=None, gamma=0, grow_policy=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=np.float64(0.3), max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=np.int64(8), max_leaves=None,\n",
       "             min_child_weight=np.int64(5), missing=nan,\n",
       "             monotone_constraints=None, multi_strategy=None,\n",
       "             n_estimators=np.int64(300), n_jobs=None, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c99d94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, \"model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
